{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Week 2 (W37) – 11.09 – 17.09 - Understand your data and your modelling goal\n",
    "- an established communication channel and appropriate strategy for code sharing.\n",
    "- data correctly imported into appropriate matrices completely: observations as rows, variables (predictors) as columns.\n",
    "- identification of challenges of the data: for example: time series not synchronized, missing values in data, extra variables, variables with unknown physical meanings, etc.\n",
    "- a visualization and comment on the dataset: variable distribution, number of observations, type of measurements (time series or not time series)\n",
    "- identification of pretreatment steps, and a plan on how to do data pretreatment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### -Importing necessary libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Load the dataset and preprocess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the dataset and preprocess\n",
    "df = pd.read_csv(\"../dataset/MiningProcess_Flotation_Plant_Database.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Displaying first few rows/observations of the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Displaying first few rows/observations of the dataset\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Number of Rows and columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rows and columns\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Print all the column names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print all the column names\n",
    "df.columns.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Convert the date column to CORRECT date-times\n",
    "- This will help for further processing of data\n",
    "- Need to convert/process 'date' column to make/form a time series"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checking the number of entries for each hour\n",
    "count_df = df.groupby(['date']).count()\n",
    "wrong_num_sample_ids = count_df.index[count_df[\"Starch Flow\"] != 180]\n",
    "# wrong_num_sample_ids\n",
    "\n",
    "# Convert the date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# The real start of recording is from 00:03:00\n",
    "DATA_COLLECT_START = df[\"date\"][0].replace(minute=3)\n",
    "\n",
    "# Fix the missing entry on 10 May 2017\n",
    "row_to_repeat = df.loc[df[\"date\"] == wrong_num_sample_ids[1]].iloc[0]\n",
    "df.loc[-1] = row_to_repeat\n",
    "df = df.sort_index()\n",
    "\n",
    "# get gaps in time\n",
    "t = pd.Timedelta('1hour')\n",
    "mask = df['date'].diff().gt(t)\n",
    "starts = df.loc[mask.shift(-1, fill_value=False), 'date'].add(t).astype(str)\n",
    "stops = df.loc[mask, 'date'].sub(t).astype(str)\n",
    "out = list(zip(starts, stops))\n",
    "\n",
    "# Get list of start-end periods fo data collection\n",
    "starts_ends = [str(DATA_COLLECT_START),\n",
    "       str(datetime.datetime.strptime(out[0][0], '%Y-%m-%d %H:%M:%S')\n",
    "           - datetime.timedelta(hours=1)),\n",
    "       str(datetime.datetime.strptime(out[0][1], '%Y-%m-%d %H:%M:%S')\n",
    "           - datetime.timedelta(seconds=20)),\n",
    "       str(df[\"date\"][df[\"date\"].idxmax()] + datetime.timedelta(hours=1))]\n",
    "\n",
    "# Get correct datetimes for dataset based on sampling rate\n",
    "dates = pd.date_range(start=starts_ends[0], end=starts_ends[1], freq='20S')\n",
    "dates = dates.union(pd.date_range(start=starts_ends[2], end=starts_ends[3], freq='20S'))\n",
    "dates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Replace date column with correct date-times and set variable as index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"date\"] = dates\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Check convertion\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Convert columns/variables to numeric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert columns/variables to numeric\n",
    "# Replace ',' by '.'\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].str.replace(',', '.').astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check convertion\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Checking datatypes of all columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checking datatypes of all columns\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Missing/null value checking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Missing/null value checking\n",
    "# All variables converted to numeric\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Cross-checking if there is any null values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cross-checking if there is any null values\n",
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Checking additional statistics- (e.g. count, mean, std, 25%, 50%,75%, min, max)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Checking additional statistics- (e.g. count, mean, std, 25%, 50%,75%, min, max)\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - Visualization (Box-Plot of all variables)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Select numeric variables\n",
    "numeric_variables = df.select_dtypes(include='number')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Create a box plot for each numeric variable\n",
    "box_plot = ax.boxplot(numeric_variables.values, vert=False, patch_artist=True)\n",
    "\n",
    "for box in box_plot['boxes']:\n",
    "    box.set(facecolor='lightblue')\n",
    "for whisker in box_plot['whiskers']:\n",
    "    whisker.set(color='black', linestyle='-', linewidth=1.2)\n",
    "for median in box_plot['medians']:\n",
    "    median.set(color='red', linewidth=1.5)\n",
    "\n",
    "ax.set_yticklabels(numeric_variables.columns)\n",
    "\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_title('Box Plot of Numeric Variables')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - Visualization (individual Box-Plot of all variables)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numeric_variables = df.select_dtypes(include='number')\n",
    "\n",
    "column_names = numeric_variables.columns\n",
    "\n",
    "# Subplots per row for better visualization\n",
    "num_cols = 4\n",
    "num_rows = len(column_names) // num_cols + 1\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 12))\n",
    "\n",
    "if num_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "# Create box plots for each numeric variable\n",
    "for i, column in enumerate(column_names):\n",
    "    row_idx = i // num_cols\n",
    "    col_idx = i % num_cols\n",
    "    ax = axes[row_idx, col_idx]\n",
    "\n",
    "    ax.boxplot(df[column], vert=False)\n",
    "    ax.set_title(column)\n",
    "    ax.set_xlabel('Value')\n",
    "\n",
    "for i in range(len(column_names), num_cols * num_rows):\n",
    "    fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### - Visualization (Histogram of all variables)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get numeric variables\n",
    "numeric_variables = df.select_dtypes(include='number')\n",
    "\n",
    "# Subplots per row for better visualization\n",
    "subplots_per_row = 4\n",
    "num_variables = len(numeric_variables.columns)\n",
    "num_rows = (num_variables + subplots_per_row - 1) // subplots_per_row\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=subplots_per_row, figsize=(16, 4 * num_rows), sharex=False)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot histograms for each numeric variable\n",
    "for i, col in enumerate(numeric_variables.columns):\n",
    "    ax = axes[i]\n",
    "    ax.hist(df[col], bins=20)\n",
    "    ax.set_title(col)\n",
    "    ax.grid(True)\n",
    "\n",
    "for i in range(num_variables, num_rows * subplots_per_row):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### - Visualization (Correlation matrix)\n",
    "- Find the relationships among variables, specially when there are huge number of observations\n",
    "-  Helpful for understanding redundant variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Select numeric variables (excluding any non-numeric columns)\n",
    "#numeric_variables = df.select_dtypes(include='number')\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Need to provde description:\n",
    "- Do we need resample or preprocess the data to make it synchronize? If yes then what is the plan?\n",
    "- Is there are any irrelevant or redundant variables that don't contribute to the analysis or prediction.\n",
    "- Identification of pretreatment steps, and a plan on how to do data pretreatment\n",
    "- Identify which variables are time series data and which are not. Time series data will have timestamps associated with them.\n",
    "- I dentify different measurement unit or scale of the variables\n",
    "- How do we deal with the different measurements/scale\n",
    "\n",
    "### Identification of Pretreatment Steps:\n",
    "\n",
    "- Handling Missing Values: If missing values are detected, decide on a strategy to handle them. Options include imputation (e.g., mean, median, forward-fill, or interpolation) or removal of rows/columns with missing values.\n",
    "- Resampling: If time series data is not synchronized, we may need to resample it to a consistent time interval.\n",
    "- Feature Selection: Assess the relevance of each variable for our analysis or modeling task. Remove any irrelevant or redundant variables.\n",
    "- Data Scaling/Normalization: Depending on the modeling techniques that we plan to use, may need to scale or normalize the data to ensure all variables have similar ranges.\n",
    "- Outlier Detection and Handling: Identify and handle outliers if they exist in the dataset. Outliers can significantly impact modeling results.\n",
    "- Data Splitting: FOr our predictive models, need to decide how to split the data into training, validation, and test sets.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}